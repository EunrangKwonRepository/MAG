{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') #warnings.filterwarnings(action='default')\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pandas import Series\n",
    "\n",
    "from scipy.stats.stats import kendalltau\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import datetime\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "\n",
    "#setting font\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loading dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tag = pd.read_table('discipline.txt',sep='\\t', header=None)\n",
    "tag = tag.reset_index(drop=True).reset_index()\n",
    "tag[3] = tag.apply(lambda x : x['index']+11, axis = 1)\n",
    "tag.columns = ['index', 'field_id', 'field', 'id2', 'id1']\n",
    "\n",
    "tag['field'] =  tag['field'].str.capitalize()\n",
    "tag['field'] = tag['field'].str.replace(\"science\", \"Science\")\n",
    "\n",
    "tag0 = dict(zip(tag.field, tag.id2))\n",
    "tag1 = dict(zip(tag.id1, tag.field))\n",
    "tag2 = dict(zip(tag.id1, tag.id2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_var = pd.read_table(\"effect_var.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##loading online dataset\n",
    "online = pd.read_table('online_0627.txt')\n",
    "\n",
    "online = online.loc[online['author_n']<= 50, :]\n",
    "online = online.loc[online['paper_type']==1, :]\n",
    "online = online.loc[online['field_id1'].notnull(), :]\n",
    "\n",
    "online[\"ye_mo\"] = online.apply(lambda x : 10*x['year2']+x['month2'], axis = 1)\n",
    "online.rename(columns = {'year2': 'year'}, inplace = True)\n",
    "\n",
    "author_role = pd.read_table('author_role_plot_on_0627.txt')\n",
    "author_role.rename(columns = {'year2': 'year'}, inplace = True)\n",
    "author_role = author_role[['paperid', 'authorid', 'sequence_number', 'year', 'field_id1', 'gender', 'author_role']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 8 ###\n",
    "- CID in Average Number of Authors and Number of Papers by Field of online preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CID in number of papers ###\n",
    "def did_cal(df):\n",
    "    paperid = df.groupby(['field_id1', 'year']).count()[['paperid']].reset_index()\n",
    "\n",
    "    sub_df = pd.DataFrame()\n",
    "    for i in range(11, 30):\n",
    "        sub_f = paperid.loc[paperid['field_id1']==i, :].reset_index(drop=True)\n",
    "        sub_f.loc['2020'] = (sub_f.loc[4][2:][0] - sub_f.loc[3][2:][0]) - (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0])\n",
    "        sub_f.loc['2019'] = (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0]) - (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0])\n",
    "        sub_f.loc['2018'] = (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0]) - (sub_f.loc[1][2:][0] - sub_f.loc[0][2:][0])\n",
    "        sub_f.loc['2020_1'] = (sub_f.loc[4][2:][0] - sub_f.loc[3][2:][0]) - (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0])\n",
    "        sub_f.loc['2019_1'] = (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0]) - (sub_f.loc[1][2:][0] - sub_f.loc[0][2:][0])\n",
    "        sub_f.loc['1819'] = sub_f.iloc[6:8, 2:].mean()[0]\n",
    "        sub_f = sub_f.reset_index()\n",
    "\n",
    "        sub_f = sub_f.iloc[5:]\n",
    "        sub_f['field'] = i\n",
    "        sub_df = pd.concat([sub_df, sub_f])\n",
    "\n",
    "    sub_df['%'] = round(sub_df['paperid'], 0)\n",
    "    sub_df = sub_df[['index','%','field']]\n",
    "\n",
    "    return sub_df\n",
    "\n",
    "### CID in average number of authors ###\n",
    "def did_cal_author_n(online):\n",
    "    df2 = online[['field_id1', 'year', 'author_n']]\n",
    "    author_n = df2.groupby(['field_id1', 'year']).mean().reset_index()\n",
    "\n",
    "    sub_df = pd.DataFrame()\n",
    "    for i in range(11, 30):\n",
    "        sub_f = author_n.loc[author_n['field_id1']==i, :].reset_index(drop=True)\n",
    "        sub_f.loc['2020'] = (sub_f.loc[4][2:][0] - sub_f.loc[3][2:][0]) - (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0])\n",
    "        sub_f.loc['2019'] = (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0]) - (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0])\n",
    "        sub_f.loc['2018'] = (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0]) - (sub_f.loc[1][2:][0] - sub_f.loc[0][2:][0])\n",
    "        sub_f.loc['2020_1'] = (sub_f.loc[4][2:][0] - sub_f.loc[3][2:][0]) - (sub_f.loc[2][2:][0] - sub_f.loc[1][2:][0])\n",
    "        sub_f.loc['2019_1'] = (sub_f.loc[3][2:][0] - sub_f.loc[2][2:][0]) - (sub_f.loc[1][2:][0] - sub_f.loc[0][2:][0])\n",
    "        sub_f.loc['1819'] = sub_f.iloc[6:8, 2:].mean()[0]\n",
    "        sub_f = sub_f.reset_index()\n",
    "\n",
    "        sub_f = sub_f.iloc[5:]\n",
    "        sub_f['field'] = i\n",
    "        sub_df = pd.concat([sub_df, sub_f])\n",
    "\n",
    "    sub_df['%'] = round(sub_df['author_n'], 3)\n",
    "    sub_df = sub_df[['index','%','field']]\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "### drawing supplementary figure 8 ###\n",
    "def graph_did1(graph, x1, y1, x3, y3, ax1):\n",
    "    sns.set(style = \"ticks\", font_scale=1.6)\n",
    "\n",
    "    g3 = sns.scatterplot(data=graph, x=x3, y=y3, s=150, marker='s', edgecolor='royalblue', linewidth=3, facecolor=\"w\", alpha=0.8, ax=ax1)\n",
    "\n",
    "    g1 = sns.scatterplot(data=graph, x=x1, y=y1, s=150, marker='o',  edgecolor='orange', linewidth=3, facecolor=\"w\", ax=ax1)\n",
    "\n",
    "    ax1.axvline(0, c='black', ls='-')\n",
    "    ax1.axhline(0, c='black', ls='-')\n",
    "\n",
    "    ax1.set_title(\"CID in Average Number of Authors(x) vs Number of Papers(y) by Field\")\n",
    "\n",
    "    ax1.set_ylabel(\"Number of Papers\")\n",
    "    ax1.set_xlabel(\"Average Number of Authors\")\n",
    " \n",
    "    blue_line = mlines.Line2D([], [], color='royalblue', linestyle='', markersize=15, label='2019', marker='s', \n",
    "                                fillstyle='none', markeredgewidth=3)\n",
    "    orange_line = mlines.Line2D([], [], color='orange',linestyle='', markersize=15, label='2020', marker='o', \n",
    "                               fillstyle='none', markeredgewidth=3)\n",
    "    \n",
    "    L = ax1.legend(handles=[blue_line, orange_line], ncol=3, fontsize=20, frameon=False, bbox_to_anchor=(0.41, -0.18), handletextpad=0.3)\n",
    "\n",
    "    ax1.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = online[['paperid', 'field_id1', 'year', 'author_n', 'female_have', 'female_first', 'female_last']]\n",
    "\n",
    "paper = did_cal(df)\n",
    "paper['cat'] = 'paper'\n",
    "author = did_cal_author_n(online)\n",
    "author['cat'] = 'author'\n",
    "graph = pd.concat([paper, author])\n",
    "\n",
    "graph['index_year'] = graph['index'] +'_' +graph['cat']\n",
    "graph['field'] = graph['field'].replace(tag1)\n",
    "\n",
    "graph = graph.pivot(index='field', columns='index_year', values='%').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### supplementary figure 8 ###\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax1 = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "graph_did1(graph, '2020_author', '2020_paper', '2019_author', '2019_paper', ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 9 ###\n",
    "- CID(%) by the role of female authors by field of study, measured with the online preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CID by author role in total cases ###\n",
    "def cal_female_per(df, female_have):\n",
    "    fe = df[['year', female_have, 'paperid']]\n",
    "    fe = fe.groupby(['year', female_have]).count()\n",
    "    fe['sum'] = fe.groupby(['year']).transform(sum)\n",
    "    fe['%'] = round(fe['paperid']/fe['sum']*100, 2)\n",
    "\n",
    "    fe =  fe.reset_index()\n",
    "    fe = fe.loc[fe[female_have]==1, :][['year', 'paperid', '%']]\n",
    "    fe = fe.sort_values(by=['year'], axis=0)\n",
    "    \n",
    "    fe['author role'] = female_have\n",
    "    fe = fe[['year', '%', 'author role']]\n",
    "    \n",
    "    fe = fe.reset_index(drop=True)\n",
    "    fe.loc['2020'] = (fe.loc[4][1:][0] - fe.loc[3][1:][0]) - (fe.loc[3][1:][0] - fe.loc[2][1:][0])\n",
    "    fe.loc['2019'] = (fe.loc[3][1:][0] - fe.loc[2][1:][0]) - (fe.loc[2][1:][0] - fe.loc[1][1:][0])\n",
    "    fe.loc['2018'] = (fe.loc[2][1:][0] - fe.loc[1][1:][0]) - (fe.loc[1][1:][0] - fe.loc[0][1:][0])\n",
    "    fe.loc['2020_1'] = (fe.loc[4][1:][0] - fe.loc[3][1:][0]) - (fe.loc[2][1:][0] - fe.loc[1][1:][0])\n",
    "    fe.loc['2019_1'] = (fe.loc[3][1:][0] - fe.loc[2][1:][0]) - (fe.loc[1][1:][0] - fe.loc[0][1:][0])\n",
    "    fe.loc['1819'] = fe.iloc[6:8, 1:].mean()[0]\n",
    "\n",
    "    fe = fe.reset_index()\n",
    "    fe = fe.iloc[5:, 0:]\n",
    "    fe['author role'] = female_have\n",
    "    \n",
    "    return fe\n",
    "\n",
    "### drawing supplementary figure 9_a ###\n",
    "def show_value_for_barplot(barplot, h_v=\"v\"):\n",
    "    if h_v == \"v\":\n",
    "        for p in barplot.patches:\n",
    "            barplot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "    elif h_v == \"h\":\n",
    "        for p in barplot.patches:\n",
    "            barplot.annotate(format(p.get_width(), '.2f'), (p.get_width(), p.get_y()+ p.get_height() / 2.), ha = 'center', va = 'center', xytext = (18, 0), textcoords = 'offset points')\n",
    "\n",
    "            \n",
    "def graph_did2_a(female2, ax1):\n",
    "    sns.set(style = \"ticks\", font_scale=2.0)\n",
    "\n",
    "    sns.barplot(x ='DID', y = 'Female Author Role', hue = 'index', data = female2,  orient='h', ci= False, ax = ax1)\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.set_xlim([-0.5,1])\n",
    "    ax1.axvline(0, c='black', ls='-')\n",
    "\n",
    "    for y1 in range(0, 4):\n",
    "        ax1.patches[y1].set_facecolor('royalblue')\n",
    "    for y2 in range(4, 8):\n",
    "        ax1.patches[y2].set_facecolor('orange')\n",
    "\n",
    "    ax1.set_xlabel('CID')\n",
    "    ax1.set_title('Total Data')\n",
    "    show_value_for_barplot(ax1, h_v=\"h\")\n",
    "    ax1.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CID by field ###\n",
    "def cal_female_per_byfield(df, female_have):\n",
    "    fe = df[['year', 'field_id1', female_have, 'paperid']]\n",
    "    fe = fe.groupby(['year', 'field_id1', female_have]).count()\n",
    "    fe['sum'] = fe.groupby(['year', 'field_id1']).transform(sum)\n",
    "    fe['%'] = round(fe['paperid']/fe['sum']*100, 2)\n",
    "\n",
    "    fe =  fe.reset_index()\n",
    "    fe = fe.loc[fe[female_have]==1, :][['year', 'field_id1', 'paperid', '%']]\n",
    "    fe = fe.sort_values(by=['field_id1', 'year'], axis=0)\n",
    "    fe['field_id1'] = fe['field_id1'].replace(tag1)\n",
    "\n",
    "    fe = fe.pivot(columns='field_id1',index=['year']).fillna(0)\n",
    "    \n",
    "    return fe\n",
    "\n",
    "### drawing supplementary figure 9_b ###\n",
    "def graph_did2_b(x1, y1, x2, y2, ax1):\n",
    "    sns.set(style = \"ticks\", font_scale=2.0)\n",
    "    \n",
    "    g2 = sns.scatterplot(data=cross, x=x2, y=y2, s=150, marker='s', edgecolor='royalblue', linewidth=3, facecolor=\"w\", alpha=0.8, ax=ax1)\n",
    "\n",
    "    g1 = sns.scatterplot(data=cross, x=x1, y=y1, s=200, marker='o',  edgecolor='orange', linewidth=3, facecolor=\"w\", ax=ax1)\n",
    "    an_df = cross.loc[(cross[x1]>=0), :].reset_index(drop=True)\n",
    "    for i in range(an_df.shape[0]):\n",
    "        g1.text(x=an_df[x1][i]+0.05,y=an_df[y1][i]+0.05,s=an_df['field_id1'][i],\n",
    "                       fontdict = dict(color='black' ,size=18))\n",
    "\n",
    "    plt.axvline(0, c='black', ls='-')\n",
    "    plt.axhline(0, c='black', ls='-')\n",
    "\n",
    "    plt.title(\"CID in % First Author(x) vs Last Author(y) by Field\", fontsize=24)\n",
    "\n",
    "    plt.xlabel(\"First Author\")\n",
    "    plt.ylabel(\"Last Author\")\n",
    "\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = online[['paperid', 'field_id1', 'year', 'female_have', 'female_first', 'female_last']]\n",
    "\n",
    "fe_other = author_role.loc[author_role['author_role'] == '기타', :]\n",
    "fe_other = fe_other.groupby(['paperid']).sum().reset_index()\n",
    "fe_other.rename(columns = {'gender': 'female_other'}, inplace = True)\n",
    "\n",
    "fe_other = fe_other[['paperid', 'female_other']]\n",
    "fe_other[\"female_other\"] = fe_other.apply(lambda x : 0 if x['female_other']==0 else 1, axis = 1)\n",
    "\n",
    "df = pd.merge(df, fe_other, on='paperid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 9_a ###\n",
    "fe_hav = cal_female_per(df, 'female_have')\n",
    "fe_fir = cal_female_per(df, 'female_first')\n",
    "fe_las = cal_female_per(df, 'female_last')\n",
    "fe_other2 = cal_female_per(df, 'female_other')\n",
    "\n",
    "female = pd.concat([fe_hav, fe_fir, fe_las, fe_other2])\n",
    "\n",
    "female.loc[female['author role']=='female_have', 'author role'] = 'Any'\n",
    "female.loc[female['author role']=='female_first', 'author role'] = 'First'\n",
    "female.loc[female['author role']=='female_last', 'author role'] = 'Last'\n",
    "female.loc[female['author role']=='female_other', 'author role'] = 'Others'\n",
    "\n",
    "female.rename(columns = {'author role': 'Female Author Role', '%': 'DID'}, inplace = True)\n",
    "\n",
    "female2 = female.loc[(female['index']=='2020')|(female['index']=='2019'), :]\n",
    "\n",
    "female2 = female2.sort_values(\"index\")\n",
    "female2 = female2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 9_b ###\n",
    "fe_hav = cal_female_per_byfield(df, 'female_have')\n",
    "fe_fir = cal_female_per_byfield(df, 'female_first')\n",
    "fe_las = cal_female_per_byfield(df, 'female_last')\n",
    "\n",
    "female_2_b = pd.concat([fe_hav, fe_fir, fe_las])\n",
    "\n",
    "percent = female_2_b['%'][['History', 'Philosophy', 'Art', 'Economics', 'Sociology', 'Political Science', 'Psychology', 'Business', 'Chemistry', \n",
    "                       'Materials Science', 'Computer Science', 'Engineering', 'Geology', 'Geography', 'Mathematics', 'Biology', \n",
    "                       'Environmental Science', 'Physics', 'Medicine']].reset_index()\n",
    "paperid = female_2_b['paperid'][['History', 'Philosophy', 'Art', 'Economics', 'Sociology', 'Political Science', 'Psychology', 'Business', 'Chemistry',\n",
    "                       'Materials Science', 'Computer Science', 'Engineering', 'Geology', 'Geography', 'Mathematics', 'Biology', \n",
    "                       'Environmental Science', 'Physics', 'Medicine']].reset_index()\n",
    "\n",
    "female_2_b = pd.concat([percent, paperid])\n",
    "field_box = female_2_b.iloc[5:15]\n",
    "\n",
    "#female first\n",
    "field_box = female_2_b.iloc[5:15]\n",
    "field_box.loc['2020_first'] = (field_box.loc[9] - field_box.loc[8]) - (field_box.loc[8] - field_box.loc[7])\n",
    "field_box.loc['2019_first'] = (field_box.loc[8] - field_box.loc[7]) - (field_box.loc[7] - field_box.loc[6])\n",
    "field_box.loc['2018_first'] = (field_box.loc[7] - field_box.loc[6]) - (field_box.loc[6] - field_box.loc[5])\n",
    "field_box.loc['2020_1_first'] = (field_box.loc[9] - field_box.loc[8]) - (field_box.loc[7] - field_box.loc[6])\n",
    "field_box.loc['2019_1_first'] = (field_box.loc[8] - field_box.loc[7]) - (field_box.loc[6] - field_box.loc[5])\n",
    "field_box.loc['1819_first'] = field_box.iloc[11:13, 1:].mean()\n",
    "female_first = field_box.iloc[10:, 1:].T\n",
    "\n",
    "#female last\n",
    "field_box = female_2_b.iloc[5:15]\n",
    "field_box.loc['2020_last'] = (field_box.loc[14] - field_box.loc[13]) - (field_box.loc[13] - field_box.loc[12])\n",
    "field_box.loc['2019_last'] = (field_box.loc[13] - field_box.loc[12]) - (field_box.loc[12] - field_box.loc[11])\n",
    "field_box.loc['2018_last'] = (field_box.loc[12] - field_box.loc[11]) - (field_box.loc[11] - field_box.loc[10])\n",
    "field_box.loc['2020_1_last'] = (field_box.loc[14] - field_box.loc[13]) - (field_box.loc[12] - field_box.loc[11])\n",
    "field_box.loc['2019_1_last'] = (field_box.loc[13] - field_box.loc[12]) - (field_box.loc[11] - field_box.loc[10])\n",
    "field_box.loc['1819_last'] = field_box.iloc[11:13, 1:].mean()\n",
    "female_last = field_box.iloc[10:, 1:].T\n",
    "\n",
    "cross = pd.concat([female_first, female_last], axis=1)\n",
    "cross = cross.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### supplementary figure 9 ###\n",
    "fig = plt.figure(constrained_layout=True, figsize=(18, 8))\n",
    "spec = gridspec.GridSpec(ncols=14, nrows=15, figure=fig)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0:15, 0:5])\n",
    "ax2 = fig.add_subplot(spec[0:15, 6:15])\n",
    "\n",
    "graph_did2_a(female2, ax1)\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "L = ax1.legend(ncol=2, fontsize=24, bbox_to_anchor=(0.89, -0.18), frameon=False) #handles = []\n",
    "\n",
    "graph_did2_b('2020_first', '2020_last', '2019_first', '2019_last', ax2)\n",
    "blue_line = mlines.Line2D([], [], color='royalblue', linestyle='', markersize=15, label='2019', marker='s', \n",
    "                            fillstyle='none', markeredgewidth=3)\n",
    "orange_line = mlines.Line2D([], [], color='orange',linestyle='', markersize=15, label='2020', marker='o', \n",
    "                           fillstyle='none', markeredgewidth=3)\n",
    "                        \n",
    "L = ax2.legend(handles=[blue_line, orange_line], ncol=3, fontsize=24, frameon=False, bbox_to_anchor=(0.48, -0.18),\n",
    "              handletextpad=0.3)\n",
    "\n",
    "labellist = [f\"{x}\" for x in string.ascii_lowercase]\n",
    "for idx, now_ax in enumerate(fig.get_axes()):\n",
    "    now_ax.text(-0.09, 1.02, labellist[idx], fontsize=24, weight='bold', transform=now_ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 10 ###\n",
    "- CID(%) for female first authors by their characteristics of online preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CID for % female first authors by first-author’s characteristics ###\n",
    "def did_cal_byvar(df, five, female_have, effect_var):\n",
    "    df2 = df[['paperid', 'year', 'female_have', 'female_first', 'female_last', five]]\n",
    "    df2 = df2.loc[df2[five].notnull(), :]\n",
    "\n",
    "    if effect_var == 'aca_age':\n",
    "        df2.loc[df2[five]<10, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=10)&(df2[five]<20), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=20)&(df2[five]<30), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=30, 'set'] = 'set4'\n",
    "    elif effect_var == 'aut_hidx':\n",
    "        df2.loc[df2[five]<2, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=2)&(df2[five]<4), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=4)&(df2[five]<8), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=8, 'set'] = 'set4'\n",
    "    else:\n",
    "        df2.loc[df2[five]<st[0], 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=st[0])&(df2[five]<st[1]), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=st[1])&(df2[five]<st[2]), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=st[2], 'set'] = 'set4'\n",
    "\n",
    "    fe_hav = df2[['year', female_have, 'paperid', 'set']]\n",
    "    fe_hav = fe_hav.groupby(['year', female_have, 'set']).count()\n",
    "\n",
    "    fe_hav['sum'] = fe_hav.groupby(['year', 'set']).transform(sum)\n",
    "    fe_hav['%'] = round(fe_hav['paperid']/fe_hav['sum']*100, 2) #sum: 남자 + 여자\n",
    "\n",
    "    fe_hav =  fe_hav.reset_index()\n",
    "    fe_hav = fe_hav.loc[fe_hav[female_have]==1, :][['year', 'set', '%']]\n",
    "    fe_hav = fe_hav.sort_values(by=['year'], axis=0)\n",
    "\n",
    "    effect_val = ['set1', 'set2', 'set3', 'set4']\n",
    "\n",
    "    df3 = pd.DataFrame()\n",
    "    for x in effect_val:\n",
    "        did = fe_hav.loc[fe_hav['set']==x, :].reset_index(drop=True)\n",
    "\n",
    "        did.loc['2018'] = (did.loc[2][2:] - did.loc[1][2:]) - (did.loc[1][2:] - did.loc[0][2:])\n",
    "        did.loc['2019'] = (did.loc[3][2:] - did.loc[2][2:]) - (did.loc[2][2:] - did.loc[1][2:])\n",
    "        did.loc['2020'] = (did.loc[4][2:] - did.loc[3][2:]) - (did.loc[3][2:] - did.loc[2][2:])\n",
    "        did.loc['2020_1'] = (did.loc[4][2:] - did.loc[3][2:]) - (did.loc[2][2:] - did.loc[1][2:])\n",
    "        did.loc['2019_1'] = (did.loc[3][2:] - did.loc[2][2:]) - (did.loc[1][2:] - did.loc[0][2:])\n",
    "\n",
    "        did = did.iloc[5:, 2:]\n",
    "        did['set'] = x\n",
    "        did['author_role'] = female_have\n",
    "        did['cat'] = five\n",
    "\n",
    "        df3 = pd.concat([df3, did])\n",
    "        \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Calculating CID for % female first authors by first-author’s characteristics ###\n",
    "effect_var_list = ['aca_age', 'aut_hidx', 'aff_hidx', 'ggis1', 'total_cases_per_million', 'total_deaths_per_million']\n",
    "\n",
    "var_name_list = ['Academic Age', 'Author h-index', 'Affiliation h-index', 'Gender Equality', 'Total Cases Per Million', 'Total Deaths Per Million']\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for effect_var in effect_var_list:\n",
    "    var = df_var[['authorid', effect_var]].dropna(axis=0) #null 제외\n",
    "    var = var.drop_duplicates()\n",
    "    var2 = var[effect_var]\n",
    "    st = list(var2.quantile([.25, .50,.75]))\n",
    "\n",
    "    df = online[['paperid', 'year', 'female_have', 'female_first', 'female_last']]\n",
    "\n",
    "    author_role2 = author_role\n",
    "\n",
    "    author_role2 = pd.merge(author_role2, var, on='authorid', how='left')\n",
    "\n",
    "    author_role2 = author_role2.loc[author_role2[effect_var].notnull(), :]\n",
    "\n",
    "    #최대, 최소, 평균, 제1저자, 교신저자\n",
    "    fir = author_role2.loc[author_role2['author_role']=='제1', :][['paperid', effect_var]]\n",
    "    las = author_role2.loc[author_role2['author_role']=='교신', :][['paperid', effect_var]]\n",
    "    mean_val = author_role2.groupby(['paperid']).mean().reset_index()[['paperid', effect_var]]\n",
    "\n",
    "    five_val = pd.merge(fir, las, on='paperid', how='left')\n",
    "    five_val = pd.merge(five_val, mean_val, on='paperid', how='left')\n",
    "    five_val.columns = ['paperid', 'fir', 'las', 'mean']\n",
    "\n",
    "    df = pd.merge(df, five_val, on='paperid', how='left')\n",
    "\n",
    "    five_list = ['fir', 'las', 'mean']\n",
    "\n",
    "    graph = pd.DataFrame()\n",
    "    \n",
    "    for five in five_list:\n",
    "        gra1 = did_cal_byvar(df, five, 'female_have', effect_var)\n",
    "        gra2 = did_cal_byvar(df, five, 'female_first', effect_var)\n",
    "        gra3 = did_cal_byvar(df, five, 'female_last', effect_var)\n",
    "\n",
    "        graph = pd.concat([graph, gra1, gra2, gra3])\n",
    "        \n",
    "        df3_s = pd.DataFrame()\n",
    "\n",
    "    effect_val = ['set1', 'set2', 'set3', 'set4']\n",
    "\n",
    "    for i in effect_val:\n",
    "        df0 = graph.loc[graph['set']==i, :]\n",
    "\n",
    "        for five in five_list:\n",
    "            df2_s = df0.loc[df0['cat']==five, :].reset_index()\n",
    "\n",
    "            df2_s.loc[15] = (df2_s.loc[0][1:2] + df2_s.loc[1][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_have'\n",
    "\n",
    "            df2_s.loc[16] = (df2_s.loc[5][1:2] + df2_s.loc[6][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_first'\n",
    "\n",
    "            df2_s.loc[17] = (df2_s.loc[10][1:2] + df2_s.loc[11][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_last'\n",
    "\n",
    "            df2_s.loc[df2_s['index'].isnull(), 'index'] = '1819'\n",
    "            df2_s['set'] = i\n",
    "            df2_s['cat'] = five\n",
    "\n",
    "            df2_s['head'] = df2_s['index'] +\"_\"+ df2_s['author_role']\n",
    "            \n",
    "            df3_s = pd.concat([df3_s, df2_s])\n",
    "\n",
    "    df3_s = df3_s.reset_index(drop= True)\n",
    "    df3_s['head'] = df3_s['author_role'] + \":\" +df3_s['cat']\n",
    "\n",
    "    df3_s.rename(columns = {'%': 'DID', 'set':'SET'}, inplace = True)\n",
    "\n",
    "    df3_s.loc[df3_s['SET']=='set1', 'SET'] = 'Group1'\n",
    "    df3_s.loc[df3_s['SET']=='set2', 'SET'] = 'Group2'\n",
    "    df3_s.loc[df3_s['SET']=='set3', 'SET'] = 'Group3'\n",
    "    df3_s.loc[df3_s['SET']=='set4', 'SET'] = 'Group4'\n",
    "    \n",
    "    df3_s = df3_s.loc[df3_s['head']=='female_first:fir', :] ### \n",
    "    df3_s['effect_var'] = effect_var\n",
    "    \n",
    "    df_total = pd.concat([df_total, df3_s])\n",
    "    \n",
    "    print(effect_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### drawing supplementary figure 10 ###\n",
    "def graph_did3(df3, category, var_name, ax_number, set1_ex, set4_ex):\n",
    "    sns.set(style = \"ticks\", font_scale=1.6)\n",
    "\n",
    "    sns_df = df3.loc[df3['effect_var']==category, :]\n",
    "    sns_df.loc[sns_df['SET']=='Group1', \"SET\"] = set1_ex\n",
    "    sns_df.loc[sns_df['SET']=='Group4', \"SET\"] = set4_ex\n",
    "\n",
    "    sns.barplot(x ='DID', y = 'SET', hue = 'index', data = sns_df,  orient='h', ci= False, ax=ax_number)\n",
    "    ax_number.grid()\n",
    "\n",
    "    ax_number.set_xlim([-3, 3])\n",
    "    ax_number.axvline(0, c='black', ls='-')\n",
    "\n",
    "    for y1 in range(0, 4):\n",
    "        ax_number.patches[y1].set_facecolor('royalblue')  \n",
    "    for y2 in range(4, 8):\n",
    "        ax_number.patches[y2].set_facecolor('orange')\n",
    "        \n",
    "    ax_number.set(xlabel=None)\n",
    "    ax_number.set(ylabel=None)\n",
    "\n",
    "    ax_number.set_title(var_name)\n",
    "    show_value_for_barplot(ax_number,h_v=\"h\")\n",
    "    \n",
    "    ax_number.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### supplementary figure 10 ###\n",
    "df_total2 = df_total.loc[(df_total['index']=='2020')|(df_total['index']=='2019')]\n",
    "df_total2 = df_total2.sort_values(['index', 'SET'])\n",
    "\n",
    "fig = plt.figure(figsize=(16, 13))\n",
    "ax1 = fig.add_subplot(2, 3, 1)\n",
    "ax2 = fig.add_subplot(2, 3, 2)\n",
    "ax3 = fig.add_subplot(2, 3, 3)\n",
    "ax4 = fig.add_subplot(2, 3, 4)\n",
    "ax5 = fig.add_subplot(2, 3, 5)\n",
    "ax6 = fig.add_subplot(2, 3, 6)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.35, hspace=0.25)\n",
    "\n",
    "graph_did3(df_total2, effect_var_list[0], var_name_list[0], ax1, 'Group1\\n(Early)', 'Group4\\n(Late)')\n",
    "graph_did3(df_total2, effect_var_list[1], var_name_list[1], ax2, 'Group1\\n(Low)', 'Group4\\n(High)')\n",
    "graph_did3(df_total2, effect_var_list[2], var_name_list[2], ax3, 'Group1\\n(Low)', 'Group4\\n(High)')\n",
    "graph_did3(df_total2, effect_var_list[3], var_name_list[3], ax4, 'Group1\\n(Low)', 'Group4\\n(High)')\n",
    "graph_did3(df_total2, effect_var_list[4], var_name_list[4], ax5, 'Group1\\n(Small)', 'Group4\\n(Large)')\n",
    "graph_did3(df_total2, effect_var_list[5], var_name_list[5], ax6, 'Group1\\n(Small)', 'Group4\\n(Large)')\n",
    "\n",
    "sns.set(style = \"ticks\", font_scale=1.6)\n",
    "    \n",
    "handles, labels = ax4.get_legend_handles_labels()\n",
    "L = ax4.legend(ncol=3, fontsize=20, bbox_to_anchor=(1.07, -0.18), frameon=False)\n",
    "\n",
    "labellist = [f\"{x}\" for x in string.ascii_lowercase]\n",
    "for idx, now_ax in enumerate(fig.get_axes()):\n",
    "    now_ax.text(-0.15, 1.02, labellist[idx], fontsize=20, weight='bold', transform=now_ax.transAxes) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 11 ###\n",
    "- The relation between the COVID-19 related factors and the mobility along with the CIDs for female first authors by their mobility measured with the online preprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### drawing supplementary figure 11 a and b ###\n",
    "def graph_did4_a(df, x1, x2, y, ax_number):\n",
    "    sns.set(style = \"ticks\", font_scale=2.0)\n",
    "\n",
    "    g1 = sns.scatterplot(data=df, x=x1, y=y, s=150,  \n",
    "                         marker='p',  edgecolor='#7fcdbb', linewidth=3, facecolor=\"w\", alpha=0.8, ax=ax_number)\n",
    "    g2 = sns.scatterplot(data=df, x=x2, y=y, s=150,  \n",
    "                         marker='^',  edgecolor='#edf8b1', linewidth=3, facecolor=\"w\", alpha=0.8, ax=ax_number)\n",
    "\n",
    "    ax_number.set_xscale(\"log\")\n",
    "\n",
    "    ax_number.axvline(0, c='black', ls='-')\n",
    "    ax_number.axhline(0, c='black', ls='-')\n",
    "\n",
    "    ax_number.set_title(\"Scatterplot of \"+y)\n",
    "\n",
    "    ax_number.set_xlabel(\"Log(Number of Person)\")  # remove the axis label\n",
    "    ax_number.set_ylabel(\"Δ Mobility(\"+y+\")\")    \n",
    "    ax_number.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 11 c and d ###\n",
    "def set_count(df, five, female_have, effect_var):\n",
    "    df2 = df[['paperid', 'year', 'female_have', 'female_first', 'female_last', five]]\n",
    "    df2 = df2.loc[df2[five].notnull(), :]\n",
    "\n",
    "    if effect_var == 'aca_age':\n",
    "        df2.loc[df2[five]<10, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=10)&(df2[five]<20), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=20)&(df2[five]<30), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=30, 'set'] = 'set4'\n",
    "    elif effect_var == 'aut_hidx':\n",
    "        df2.loc[df2[five]<2, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=2)&(df2[five]<4), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=4)&(df2[five]<8), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=8, 'set'] = 'set4'\n",
    "    else:\n",
    "        df2.loc[df2[five]<st[0], 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=st[0])&(df2[five]<st[1]), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=st[1])&(df2[five]<st[2]), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=st[2], 'set'] = 'set4'\n",
    "\n",
    "    fe_hav = df2[['year', female_have, 'paperid', 'set']]\n",
    "    \n",
    "    return fe_hav\n",
    "\n",
    "### drawing supplementary figure 11 c and d ###\n",
    "def box_plot_4c(covid2, y, ax):\n",
    "    sns.set(style = \"ticks\", font_scale=2.0)\n",
    "    sns.boxplot(x=\"set\", y=y, hue=\"effect_var\", data=covid2, palette=\"Set3\", ax=ax)\n",
    "\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax.set_title(\"Boxplot of \"+y)\n",
    "    ax.set(xlabel=None)  # remove the axis label\n",
    "    ax.set_ylabel(\"Δ Mobility(\"+y+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 11 e and f ###\n",
    "def did_cal4_e(df, five, female_have, effect_var):\n",
    "    df2 = df[['paperid', 'year', 'female_have', 'female_first', 'female_last', five]]\n",
    "    df2 = df2.loc[df2[five].notnull(), :]\n",
    "\n",
    "    if effect_var == 'aca_age':\n",
    "        df2.loc[df2[five]<10, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=10)&(df2[five]<20), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=20)&(df2[five]<30), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=30, 'set'] = 'set4'\n",
    "    elif effect_var == 'aut_hidx':\n",
    "        df2.loc[df2[five]<2, 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=2)&(df2[five]<4), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=4)&(df2[five]<8), 'set'] = 'set3'\n",
    "        df2.loc[df2[give]>=8, 'set'] = 'set4'\n",
    "    else:\n",
    "        df2.loc[df2[five]<st[0], 'set'] = 'set1'\n",
    "        df2.loc[(df2[five]>=st[0])&(df2[five]<st[1]), 'set'] = 'set2'\n",
    "        df2.loc[(df2[five]>=st[1])&(df2[five]<st[2]), 'set'] = 'set3'\n",
    "        df2.loc[df2[five]>=st[2], 'set'] = 'set4'\n",
    "\n",
    "    fe_hav = df2[['year', female_have, 'paperid', 'set']]\n",
    "    fe_hav = fe_hav.groupby(['year', female_have, 'set']).count()\n",
    "\n",
    "    fe_hav['sum'] = fe_hav.groupby(['year', 'set']).transform(sum)\n",
    "    fe_hav['%'] = round(fe_hav['paperid']/fe_hav['sum']*100, 2) #sum: 남자 + 여자\n",
    "\n",
    "    fe_hav =  fe_hav.reset_index()\n",
    "    fe_hav = fe_hav.loc[fe_hav[female_have]==1, :][['year', 'set', '%']]\n",
    "    fe_hav = fe_hav.sort_values(by=['year'], axis=0)\n",
    "\n",
    "    effect_val = ['set1', 'set2', 'set3', 'set4']\n",
    "\n",
    "    df3 = pd.DataFrame()\n",
    "    for x in effect_val:\n",
    "        did = fe_hav.loc[fe_hav['set']==x, :].reset_index(drop=True)\n",
    "\n",
    "        did.loc['2018'] = (did.loc[2][2:] - did.loc[1][2:]) - (did.loc[1][2:] - did.loc[0][2:])\n",
    "        did.loc['2019'] = (did.loc[3][2:] - did.loc[2][2:]) - (did.loc[2][2:] - did.loc[1][2:])\n",
    "        did.loc['2020'] = (did.loc[4][2:] - did.loc[3][2:]) - (did.loc[3][2:] - did.loc[2][2:])\n",
    "        did.loc['2020_1'] = (did.loc[4][2:] - did.loc[3][2:]) - (did.loc[2][2:] - did.loc[1][2:])\n",
    "        did.loc['2019_1'] = (did.loc[3][2:] - did.loc[2][2:]) - (did.loc[1][2:] - did.loc[0][2:])\n",
    "\n",
    "        did = did.iloc[5:, 2:]\n",
    "        did['set'] = x\n",
    "        did['author_role'] = female_have\n",
    "        did['cat'] = five\n",
    "\n",
    "        df3 = pd.concat([df3, did])\n",
    "        \n",
    "    return df3\n",
    "\n",
    "### drawing supplementary figure 11 e and f ###\n",
    "def graph_did_4e(df3, category, var_name, ax_number, set1_ex, set4_ex):\n",
    "    sns.set(style = \"ticks\", font_scale=2.0)\n",
    "\n",
    "    sns_df = df3.loc[df3['effect_var']==category, :]\n",
    "    sns_df.loc[sns_df['SET']=='Group1', \"SET\"] = set1_ex\n",
    "    sns_df.loc[sns_df['SET']=='Group4', \"SET\"] = set4_ex\n",
    "\n",
    "    sns.barplot(x ='DID', y = 'SET', hue = 'index', data = sns_df,  orient='h', ci= False, ax=ax_number)\n",
    "    ax_number.grid()\n",
    "\n",
    "    ax_number.set_xlim([-2, 6])\n",
    "    ax_number.axvline(0, c='black', ls='-')\n",
    "\n",
    "    for y1 in range(0, 4):\n",
    "        ax_number.patches[y1].set_facecolor('royalblue')  \n",
    "    for y2 in range(4, 8):\n",
    "        ax_number.patches[y2].set_facecolor('orange')\n",
    "        \n",
    "    ax_number.set_title(\"CID of \"+var_name)\n",
    "    ax_number.set(ylabel= None)  # remove the axis label\n",
    "    ax_number.set_xlabel(\"CID\")\n",
    "\n",
    "    #ax_number.set_title(var_name)\n",
    "    show_value_for_barplot(ax_number,h_v=\"h\")\n",
    "    \n",
    "    ax_number.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### set dataset for supplementary figure 11 a and b ###\n",
    "scatter = df_var[['iso_code_3', 'total_cases_per_million', 'total_deaths_per_million', 'Workplace', 'Residential']]\n",
    "scatter = scatter.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 11 c and d ###\n",
    "effect_var_list = ['total_cases_per_million', 'total_deaths_per_million']\n",
    "var_name_list = ['Total Cases Per Million', 'Total Deaths Per Million']\n",
    "\n",
    "covid2 = pd.DataFrame()\n",
    "\n",
    "for effect_var in effect_var_list:\n",
    "    var = df_var[['authorid', effect_var]].dropna(axis=0) #null 제외\n",
    "    var = var.drop_duplicates()\n",
    "    var2 = var[effect_var]\n",
    "    st = list(var2.quantile([.25, .50,.75]))\n",
    "\n",
    "    df = online[['paperid', 'year', 'female_have', 'female_first', 'female_last']]\n",
    "\n",
    "    author_role2 = author_role\n",
    "\n",
    "    author_role2 = pd.merge(author_role2, var, on='authorid', how='left')\n",
    "\n",
    "    author_role2 = author_role2.loc[author_role2[effect_var].notnull(), :]\n",
    "\n",
    "    #최대, 최소, 평균, 제1저자, 교신저자\n",
    "    fir = author_role2.loc[author_role2['author_role']=='제1', :][['paperid', effect_var]]\n",
    "    las = author_role2.loc[author_role2['author_role']=='교신', :][['paperid', effect_var]]\n",
    "    mean_val = author_role2.groupby(['paperid']).mean().reset_index()[['paperid', effect_var]]\n",
    "\n",
    "    five_val = pd.merge(fir, las, on='paperid', how='left')\n",
    "    five_val = pd.merge(five_val, mean_val, on='paperid', how='left')\n",
    "    five_val.columns = ['paperid', 'fir', 'las', 'mean']\n",
    "\n",
    "    df = pd.merge(df, five_val, on='paperid', how='left')\n",
    "\n",
    "    effect_val = ['set1', 'set2', 'set3', 'set4']\n",
    "    \n",
    "    gra2 = set_count(df, 'fir', 'female_first', effect_var)\n",
    "    gra2['effect_var'] = effect_var\n",
    "    \n",
    "    covid2 = pd.concat([covid2, gra2])\n",
    "\n",
    "    print(effect_var)\n",
    "    \n",
    "first = author_role.loc[author_role['author_role']=='제1', :]\n",
    "\n",
    "df_var = df_var.drop_duplicates()\n",
    "mov = df_var[['authorid', 'Workplace', 'Residential']]\n",
    "\n",
    "first = pd.merge(first, mov, on='authorid', how='left')\n",
    "\n",
    "covid2.loc[covid2['set']=='set1', 'set'] = 'Group1'\n",
    "covid2.loc[covid2['set']=='set2', 'set'] = 'Group2'\n",
    "covid2.loc[covid2['set']=='set3', 'set'] = 'Group3'\n",
    "covid2.loc[covid2['set']=='set4', 'set'] = 'Group4'\n",
    "\n",
    "covid2 = pd.merge(covid2, first, on='paperid', how='left')\n",
    "covid2 = covid2.drop(['year_y', 'authorid', 'field_id1', 'gender'], axis=1)\n",
    "covid2.rename(columns = {'year_x': 'year'}, inplace = True)\n",
    "\n",
    "covid2 = covid2.loc[covid2['year']==2020, :]\n",
    "covid2 = covid2.sort_values(['set'])\n",
    "covid2 = covid2.sort_values(['set', 'effect_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### calculating supplementary figure 11 e and f ###\n",
    "effect_var_list = ['Workplace', 'Residential']\n",
    "var_name_list = ['Workplace', 'Residential']\n",
    "\n",
    "df_total = pd.DataFrame()\n",
    "\n",
    "for effect_var in effect_var_list:\n",
    "    var = df_var[['authorid', effect_var]].dropna(axis=0) #null 제외\n",
    "    var = var.drop_duplicates()\n",
    "    var2 = var[effect_var]\n",
    "    st = list(var2.quantile([.25, .50,.75]))\n",
    "\n",
    "    df = online[['paperid', 'year', 'female_have', 'female_first', 'female_last']]\n",
    "\n",
    "    author_role2 = author_role\n",
    "\n",
    "    author_role2 = pd.merge(author_role2, var, on='authorid', how='left')\n",
    "\n",
    "    author_role2 = author_role2.loc[author_role2[effect_var].notnull(), :]\n",
    "\n",
    "    #최대, 최소, 평균, 제1저자, 교신저자\n",
    "    fir = author_role2.loc[author_role2['author_role']=='제1', :][['paperid', effect_var]]\n",
    "    las = author_role2.loc[author_role2['author_role']=='교신', :][['paperid', effect_var]]\n",
    "    mean_val = author_role2.groupby(['paperid']).mean().reset_index()[['paperid', effect_var]]\n",
    "\n",
    "    five_val = pd.merge(fir, las, on='paperid', how='left')\n",
    "    five_val = pd.merge(five_val, mean_val, on='paperid', how='left')\n",
    "    five_val.columns = ['paperid', 'fir', 'las', 'mean']\n",
    "\n",
    "    df = pd.merge(df, five_val, on='paperid', how='left')\n",
    "\n",
    "    five_list = ['fir', 'las', 'mean']\n",
    "\n",
    "    graph = pd.DataFrame()\n",
    "    \n",
    "    for five in five_list:\n",
    "        gra1 = did_cal4_e(df, five, 'female_have', effect_var)\n",
    "        gra2 = did_cal4_e(df, five, 'female_first', effect_var)\n",
    "        gra3 = did_cal4_e(df, five, 'female_last', effect_var)\n",
    "\n",
    "        graph = pd.concat([graph, gra1, gra2, gra3])\n",
    "        \n",
    "        df3_s = pd.DataFrame()\n",
    "\n",
    "    effect_val = ['set1', 'set2', 'set3', 'set4']\n",
    "\n",
    "    for i in effect_val:\n",
    "        df0 = graph.loc[graph['set']==i, :]\n",
    "\n",
    "        for five in five_list:\n",
    "            df2_s = df0.loc[df0['cat']==five, :].reset_index()\n",
    "\n",
    "            df2_s.loc[15] = (df2_s.loc[0][1:2] + df2_s.loc[1][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_have'\n",
    "\n",
    "            df2_s.loc[16] = (df2_s.loc[5][1:2] + df2_s.loc[6][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_first'\n",
    "\n",
    "            df2_s.loc[17] = (df2_s.loc[10][1:2] + df2_s.loc[11][1:2])/2\n",
    "            df2_s.loc[df2_s['author_role'].isnull(), 'author_role'] = 'female_last'\n",
    "\n",
    "            df2_s.loc[df2_s['index'].isnull(), 'index'] = '1819'\n",
    "            df2_s['set'] = i\n",
    "            df2_s['cat'] = five\n",
    "\n",
    "            df2_s['head'] = df2_s['index'] +\"_\"+ df2_s['author_role']\n",
    "            \n",
    "            df3_s = pd.concat([df3_s, df2_s])\n",
    "\n",
    "    df3_s = df3_s.reset_index(drop= True)\n",
    "    df3_s['head'] = df3_s['author_role'] + \":\" +df3_s['cat']\n",
    "\n",
    "    df3_s.rename(columns = {'%': 'DID', 'set':'SET'}, inplace = True)\n",
    "\n",
    "    df3_s.loc[df3_s['SET']=='set1', 'SET'] = 'Group1'\n",
    "    df3_s.loc[df3_s['SET']=='set2', 'SET'] = 'Group2'\n",
    "    df3_s.loc[df3_s['SET']=='set3', 'SET'] = 'Group3'\n",
    "    df3_s.loc[df3_s['SET']=='set4', 'SET'] = 'Group4'\n",
    "    \n",
    "    df3_s = df3_s.loc[df3_s['head']=='female_first:fir', :]\n",
    "    df3_s['effect_var'] = effect_var\n",
    "    \n",
    "    df_total = pd.concat([df_total, df3_s])\n",
    "    \n",
    "    print(effect_var)\n",
    "    \n",
    "dm1 = df_total.loc[df_total['index']=='2019', :]\n",
    "dm2 = df_total.loc[df_total['index']=='2020', :]\n",
    "df_total2 = pd.concat([dm1, dm2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### supplementary figure 11 ###\n",
    "fig = plt.figure(constrained_layout=True, figsize=(17, 16))\n",
    "spec = gridspec.GridSpec(ncols=14, nrows=14, figure=fig)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0:7, 0:4])\n",
    "ax2 = fig.add_subplot(spec[7:14, 0:4])\n",
    "ax3 = fig.add_subplot(spec[0:7, 5:9])\n",
    "ax4 = fig.add_subplot(spec[7:14, 5:9])\n",
    "ax5 = fig.add_subplot(spec[0:7, 10:14])\n",
    "ax6 = fig.add_subplot(spec[7:14, 10:14])\n",
    "\n",
    "graph_did4_a(scatter, 'total_cases_per_million', 'total_deaths_per_million', 'Workplace', ax1)\n",
    "white_spot = mlines.Line2D([], [], color='#FFFF',linestyle='', markersize=15, fillstyle='none', markeredgewidth=3)\n",
    "L = ax1.legend(handles=[white_spot], ncol=1, fontsize=20, frameon=False, bbox_to_anchor=(0.98, -0.13))\n",
    "\n",
    "graph_did4_a(scatter, 'total_cases_per_million', 'total_deaths_per_million', 'Residential', ax2)\n",
    "green_spot = mlines.Line2D([], [], color='#7fcdbb',linestyle='', markersize=15, label='Total Cases Per Million', marker='p', \n",
    "                           fillstyle='none', markeredgewidth=3)\n",
    "yellow_spot = mlines.Line2D([], [], color='#edf8b1', linestyle='', markersize=15, label='Total Deaths Per Million', marker='^', \n",
    "                            fillstyle='none', markeredgewidth=3)\n",
    "L = ax2.legend(handles=[green_spot, yellow_spot], ncol=1, fontsize=24, frameon=False, bbox_to_anchor=(1.1, -0.18))\n",
    "\n",
    "box_plot_4c(covid2, 'Workplace', ax3)\n",
    "box_plot_4c(covid2, 'Residential', ax4)\n",
    "L = ax4.legend(ncol=1, fontsize=24, bbox_to_anchor=(1.15, -0.18), frameon=False)\n",
    "L.get_texts()[0].set_text('Total Cases Per Million')\n",
    "L.get_texts()[1].set_text('Total Deaths Per Million')\n",
    "\n",
    "graph_did_4e(df_total2, effect_var_list[0], var_name_list[0], ax5, 'Group1\\n(Low)', 'Group4\\n(High)')\n",
    "graph_did_4e(df_total2, effect_var_list[1], var_name_list[1], ax6, 'Group1\\n(Low)', 'Group4\\n(High)')\n",
    "handles, labels = ax6.get_legend_handles_labels()\n",
    "L = ax6.legend(ncol=1, fontsize=24, bbox_to_anchor=(0.48, -0.18), frameon=False)\n",
    "\n",
    "spec.update(left=0.05, right=0.8, wspace=0.05)\n",
    "\n",
    "labellist = [f\"{x}\" for x in string.ascii_lowercase]\n",
    "for idx, now_ax in enumerate(fig.get_axes()):\n",
    "    now_ax.text(-0.15, 1.02, labellist[idx], fontsize=28, weight='bold', transform=now_ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 12 ###\n",
    "- Feature importance by female author’s characteristics measured with XGBoost of online preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from xgboost import XGBClassifier # model\n",
    "from xgboost import plot_importance # 중요변수 시각화\n",
    "from sklearn.datasets import load_boston # dataset\n",
    "from sklearn.model_selection import train_test_split # train/test\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # model 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_value_for_barplot(barplot):\n",
    "    for p in barplot.patches:\n",
    "        barplot.annotate(format(p.get_width(), '.2f'), (p.get_width(), p.get_y()+ p.get_height() / 2.), \n",
    "                         ha = 'center', va = 'center', xytext = (25, 0), textcoords = 'offset points', size= 16)   \n",
    "\n",
    "def make_table(a, b, c):\n",
    "    a_df = pd.DataFrame(a[3])\n",
    "    a_df['author_role'] = 'Any'\n",
    "    b_df = pd.DataFrame(b[3])\n",
    "    b_df['author_role'] = 'First'\n",
    "    c_df = pd.DataFrame(c[3])\n",
    "    c_df['author_role'] = 'Last'\n",
    "\n",
    "    a_df = pd.concat([a_df, b_df, c_df])\n",
    "    \n",
    "    return a_df\n",
    "\n",
    "def xgb_graph(s, ax1):\n",
    "    sns.set(style = \"ticks\", font_scale=1.6)\n",
    "\n",
    "    sns.barplot(x='feature_importance', y='author_role', hue= 'feature_name', data=s, orient='h', ax=ax1, palette='Paired', ci=None)\n",
    "    ax1.get_legend().remove()\n",
    "    ax1.set(ylabel=None)\n",
    "    ax1.set(xlabel=None)\n",
    "    ax1.set_title(s['year'][0])\n",
    "\n",
    "    show_value_for_barplot(ax1)\n",
    "    ax1.set_xlim([0, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###  Feature importance by female author’s characteristics measured with XGBoost ###\n",
    "def xgb2019(fe_hav, year):\n",
    "    fe_hav19 = fe_hav.loc[fe_hav['year'] == year, :]\n",
    "\n",
    "    drop_val = fe_hav19.columns\n",
    "    fe_hav19 = fe_hav19.drop(drop_val[5:9], axis=1)\n",
    "\n",
    "    cols = list(fe_hav19.columns)\n",
    "    col_x = cols[1:5]\n",
    "    col_y = cols[-1]\n",
    "\n",
    "    fe_train, fe_test = train_test_split(fe_hav19, test_size=0.1, random_state=123)\n",
    "    model = XGBClassifier(n_estimators = 1000, learning_rate = 0.1, max_depth = 7, importance_type='gain')\n",
    "    model.fit(X=fe_train[col_x], y=fe_train[col_y])\n",
    "    \n",
    "    sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "    feature_name = np.array(fe_hav19.columns[1:5])[sorted_idx]\n",
    "    feature_importance = model.feature_importances_[sorted_idx]\n",
    "\n",
    "    g = plt.barh(feature_name, feature_importance)\n",
    "\n",
    "    # Add annotation to bars\n",
    "    for i in g.patches:\n",
    "        plt.text(i.get_width()+0.01, i.get_y()+0.3,\n",
    "                 str(round((i.get_width()), 2)),\n",
    "                 fontsize=13, fontweight='bold',\n",
    "                 color='grey')\n",
    "\n",
    "    plt.xlabel(\"Xgboost Feature Importance\")\n",
    "\n",
    "    #모델 평가\n",
    "    y_pred = model.predict(fe_test[col_x]) # 예측치\n",
    "    y_true = fe_test[col_y] # 정답\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    globals()['{}'.format(str(fe_hav+year))] = {'acc':acc, 'feature_name':feature_name, 'feature_importance':feature_importance}\n",
    "    return acc, feature_name, feature_importance, globals()['{}'.format(str(fe_hav+year))]\n",
    "\n",
    "def xgb2020(fe_hav, year, number):\n",
    "    fe_hav19 = fe_hav.loc[fe_hav['year'] == year, :]\n",
    "    cols = list(fe_hav19.columns)\n",
    "    col_x = cols[1:number]\n",
    "    col_y = cols[-1]\n",
    "\n",
    "    fe_train, fe_test = train_test_split(fe_hav19, test_size=0.1, random_state=123)\n",
    "    model = XGBClassifier(n_estimators = 1000, learning_rate = 0.1, max_depth = 7, importance_type='gain')\n",
    "    model.fit(X=fe_train[col_x], y=fe_train[col_y])\n",
    "    \n",
    "    sorted_idx = model.feature_importances_.argsort()\n",
    "\n",
    "    feature_name = np.array(fe_hav19.columns[1:number])[sorted_idx]\n",
    "    feature_importance = model.feature_importances_[sorted_idx]\n",
    "\n",
    "    g = plt.barh(feature_name, feature_importance)\n",
    "\n",
    "    # Add annotation to bars\n",
    "    for i in g.patches:\n",
    "        plt.text(i.get_width()+0.01, i.get_y()+0.3,\n",
    "                 str(round((i.get_width()), 2)),\n",
    "                 fontsize=13, fontweight='bold',\n",
    "                 color='grey')\n",
    "\n",
    "    plt.xlabel(\"Xgboost Feature Importance\")\n",
    "\n",
    "    #모델 평가\n",
    "    y_pred = model.predict(fe_test[col_x]) # 예측치\n",
    "    y_true = fe_test[col_y] # 정답\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    globals()['{}'.format(str(fe_hav+year))] = {'acc':acc, 'feature_name':feature_name, 'feature_importance':feature_importance}\n",
    "    return acc, feature_name, feature_importance, globals()['{}'.format(str(fe_hav + year))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "offlog = pd.read_table('logistic_0828_on.txt')\n",
    "offlog = offlog.rename(columns = {'Workplace':'workplace', 'Residential':'residential'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#including all variables\n",
    "fe_hav = offlog[['year', 'aca_age', 'aut_hidx', 'aff_hidx', 'ggis1', 'total_cases_per_million', 'total_deaths_per_million', \n",
    "                 'workplace', 'residential', 'female_have']]\n",
    "fe_fir = offlog[['year', 'aca_age_f', 'aut_hidx_f', 'aff_hidx_f', 'ggis1_f', 'cases_f', 'deaths_f', 'work_f', 'res_f', 'female_first']]\n",
    "fe_las = offlog[['year', 'aca_age_l', 'aut_hidx_l', 'aff_hidx_l', 'ggis1_l', 'cases_l', 'deaths_l', 'work_l', 'res_l', 'female_last']]\n",
    "\n",
    "fe_hav = fe_hav.loc[fe_hav['female_have'].notnull(), :]\n",
    "fe_fir = fe_fir.loc[fe_fir['female_first'].notnull(), :]\n",
    "fe_las = fe_las.loc[fe_las['female_last'].notnull(), :]\n",
    "\n",
    "a = xgb2019(fe_hav, 2019)\n",
    "b = xgb2019(fe_fir, 2019)\n",
    "c = xgb2019(fe_las, 2019)\n",
    "\n",
    "a_df = make_table(a, b, c)\n",
    "\n",
    "d = xgb2020(fe_hav, 2020, 9)\n",
    "e = xgb2020(fe_fir, 2020, 9)\n",
    "f = xgb2020(fe_las, 2020, 9)\n",
    "\n",
    "d_df = make_table(d, e, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#including mobility\n",
    "fe_hav = offlog[['year', 'aca_age', 'aut_hidx', 'aff_hidx', 'ggis1', 'workplace', 'residential', 'female_have']]\n",
    "fe_hav = fe_hav.rename(columns = {'workplace':'work', 'residential':'res'})\n",
    "\n",
    "fe_fir = offlog[['year', 'aca_age_f', 'aut_hidx_f', 'aff_hidx_f', 'ggis1_f', 'work_f', 'res_f', 'female_first']]\n",
    "fe_las = offlog[['year', 'aca_age_l', 'aut_hidx_l', 'aff_hidx_l', 'ggis1_l', 'work_l', 'res_l', 'female_last']]\n",
    "\n",
    "fe_hav = fe_hav.loc[fe_hav['female_have'].notnull(), :]\n",
    "fe_fir = fe_fir.loc[fe_fir['female_first'].notnull(), :]\n",
    "fe_las = fe_las.loc[fe_las['female_last'].notnull(), :]\n",
    "\n",
    "d2 = xgb2020(fe_hav, 2020, 7)\n",
    "e2 = xgb2020(fe_fir, 2020, 7)\n",
    "f2 = xgb2020(fe_las, 2020, 7)\n",
    "\n",
    "d2_df = make_table(d2, e2, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#residential only\n",
    "fe_hav = offlog[['year', 'aca_age', 'aut_hidx', 'aff_hidx', 'ggis1', 'residential', 'female_have']]\n",
    "fe_hav = fe_hav.rename(columns = {'workplace':'work', 'residential':'res'})\n",
    "\n",
    "fe_fir = offlog[['year', 'aca_age_f', 'aut_hidx_f', 'aff_hidx_f', 'ggis1_f', 'res_f', 'female_first']]\n",
    "fe_las = offlog[['year', 'aca_age_l', 'aut_hidx_l', 'aff_hidx_l', 'ggis1_l', 'res_l', 'female_last']]\n",
    "\n",
    "fe_hav = fe_hav.loc[fe_hav['female_have'].notnull(), :]\n",
    "fe_fir = fe_fir.loc[fe_fir['female_first'].notnull(), :]\n",
    "fe_las = fe_las.loc[fe_las['female_last'].notnull(), :]\n",
    "\n",
    "d3 = xgb2020(fe_hav, 2020, 6)\n",
    "e3 = xgb2020(fe_fir, 2020, 6)\n",
    "f3 = xgb2020(fe_las, 2020, 6)\n",
    "\n",
    "d3_df = make_table(d3, e3, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a_df['year'] = 2019; a_df['cat'] = 'total'\n",
    "d_df['year'] = 2020; d_df['cat'] = 'total'\n",
    "d2_df['year'] = 2020; d2_df['cat'] = 'mobility'\n",
    "d3_df['year'] = 2020; d3_df['cat'] = 'residential_only'\n",
    "\n",
    "xgb = pd.concat([a_df, d_df, d2_df, d3_df])\n",
    "\n",
    "xgb[\"feature_name\"] = xgb.apply(lambda x : x['feature_name'].replace(\"_f\", \"\").replace(\"_l\", \"\"), axis = 1)\n",
    "\n",
    "dic = {'aca_age':'Academic Age', 'aut_hidx':'Author h-index', 'aff_hidx':'Affiliation h-index', 'ggis1':'Gender Equality',\n",
    "       'cases':'Total Cases Per Million', 'deaths':'Total Deaths Per Miilion', 'res':'Residential', 'work':'Workplace',\n",
    "       'total_cases_per_million':'Total Cases Per Million','total_deaths_per_million':'Total Deaths Per Miilion'}\n",
    "\n",
    "xgb['feature_name'] = xgb['feature_name'].replace(dic)\n",
    "\n",
    "xgb.to_csv(\"xgb_on.txt\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### supplementary figure 12 ###\n",
    "xgb = pd.read_csv(\"xgb_on.txt\", sep='\\t')\n",
    "xgb['var'] = xgb['feature_name'] + ';' + xgb['author_role']\n",
    "\n",
    "s1 = xgb[(xgb['cat']=='total')&(xgb['year']==2019)]\n",
    "\n",
    "s2 = xgb[(xgb['cat']=='mobility')&(xgb['year']==2020)].reset_index(drop=True)\n",
    "s2 = s2.sort_values(by=['feature_name', 'author_role']).reset_index(drop=True)\n",
    "s2 = pd.concat([s2[:3],  s2[6:9], s2[3:6], s2[9:18]])\n",
    "\n",
    "var_df = pd.DataFrame(s2['var'])\n",
    "var_df = pd.merge(var_df, s1, on='var', how='left')\n",
    "var_df = var_df[['var', 'feature_importance', 'year']]\n",
    "var_df[\"feature_name\"] = var_df.apply(lambda x : x['var'].split(\";\")[0], axis = 1)\n",
    "var_df[\"author_role\"] = var_df.apply(lambda x : x['var'].split(\";\")[1], axis = 1)\n",
    "var_df['year'] = 2019\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "xgb_graph(var_df, ax1)\n",
    "xgb_graph(s2, ax2)\n",
    "\n",
    "ax1.set_ylabel(\"Female Author Role\")\n",
    "fig.text(0.5, 0.02, 'Xgboost Feature Importance', ha='center')\n",
    "\n",
    "L = ax2.legend(ncol=3, fontsize=18, bbox_to_anchor=(0.33, -0.20), frameon=False)\n",
    "\n",
    "labellist = [f\"{x}\" for x in string.ascii_lowercase]\n",
    "for idx, now_ax in enumerate(fig.get_axes()):\n",
    "    now_ax.text(-0.15, 1.02, labellist[idx], fontsize=20, weight='bold', transform=now_ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Supplementary figure 14 ###\n",
    "- The number of papers that authors sorted in alphabetical order by their fields, measured for the online preprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###  The number of papers that authors sorted in alphabetical order by their fields ###\n",
    "author_role = pd.read_table('author_role_plot_on_0627.txt')\n",
    "author_role.rename(columns = {'year1': 'year'}, inplace = True)\n",
    "author_role = author_role[['paperid', 'authorid', 'sequence_number', 'field_id1']]\n",
    "\n",
    "author_name = pd.read_table('author_name.txt', header=None)\n",
    "author_name.rename(columns = {0: 'authorid', 1:'name'}, inplace = True)\n",
    "author_name[\"first\"] = author_name.apply(lambda x : x['name'][0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "author_role = pd.merge(author_role, author_name, on='authorid', how='left')\n",
    "\n",
    "dic = {'a':0, 'b':1, 'c':2, 'd':3, 'e':4, 'f':5, 'g':6, 'h':7, 'i':8, 'j':9, 'k':10, 'l':11, \n",
    "       'm':12, 'n':13, 'o':14, 'p':15, 'q':16, 'r':17, 's':18, 't':19, 'u':20, 'v':21, 'w':22, 'x':23, 'y':24, 'z':25}\n",
    "\n",
    "author_role['first'] = author_role['first'].replace(dic)\n",
    "\n",
    "author_role[\"first\"] = author_role.apply(lambda x : np.nan if type(x['first'])!=int else x['first'], axis = 1)\n",
    "author_role = author_role.loc[author_role['first'].notnull(), :]\n",
    "\n",
    "first = author_role.groupby(['paperid'])['first'].rank(method='first', ascending=False)\n",
    "first = pd.DataFrame(first)\n",
    "author_role[\"rank\"] = first['first']\n",
    "\n",
    "seq = author_role.groupby(['paperid'])['paperid'].rank(method='first', ascending=False)\n",
    "seq = pd.DataFrame(seq)\n",
    "author_role[\"seq\"] = seq['paperid']\n",
    "\n",
    "author_role[\"match\"] = author_role.apply(lambda x : 0 if x['rank']==x['seq'] else 1, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "author_paper = author_role.groupby(['paperid'])['match'].sum().reset_index()\n",
    "author_paper = author_paper.loc[author_paper['match']==0, :]\n",
    "\n",
    "field = author_role[['paperid', 'field_id1']].drop_duplicates()\n",
    "field['field_id1'] = field['field_id1'].replace(tag1)\n",
    "\n",
    "author_n = author_role.groupby(['paperid']).count().reset_index()\n",
    "author_n = author_n[['paperid', 'authorid']]\n",
    "author_n.rename(columns = {'authorid': 'author_n'}, inplace = True)\n",
    "\n",
    "author_n = pd.merge(author_n, author_paper, on='paperid', how='left')\n",
    "\n",
    "author_n = pd.merge(author_n, field, on='paperid', how='left')\n",
    "\n",
    "author_n.loc[author_n['match'].isnull(), 'match'] = 1\n",
    "\n",
    "author_n = author_n.loc[(author_n['author_n']!=1), :]\n",
    "author_n = author_n.groupby(['field_id1', 'author_n', 'match']).count().reset_index()\n",
    "\n",
    "author_n['paperid_log'] = author_n.apply(lambda x : math.log(x['paperid']), axis = 1)\n",
    "\n",
    "author_n = author_n.loc[(author_n['match']==0)&(author_n['author_n']<=10), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### supplementary figure 14 ###\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "fig.set_facecolor('white')\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "sns.set(style = \"ticks\", font_scale=2)\n",
    "\n",
    "sns.lineplot(x='author_n', y='paperid_log', hue='field_id1', marker='o', data=author_n,  palette=\"tab10\")\n",
    "sns.lineplot(x='author_n', y='paperid_log', marker='o', data=author_n.query(\"field_id1=='mathematics'\"), linestyle=\"--\")\n",
    "\n",
    "plt.xlabel('Number of Authors')\n",
    "plt.ylabel('Log(Number of Papers)')\n",
    "\n",
    "ax.legend()\n",
    "L = plt.legend(ncol=1, fontsize=16, frameon=False, bbox_to_anchor=(1.1, 1.03), handletextpad=0.3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
